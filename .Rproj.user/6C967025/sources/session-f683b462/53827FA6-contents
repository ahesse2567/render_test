---
title: "Popularity And Prevalence Of Gas Exchange Data Processing Methods: A Scoping Review"

# Hiding author and affiliation info per IJSM instructions.

# author:
#   - name: Anton Hesse
#     orcid: 0000-0001-8456-7343
#     corresponding: true
#     email: hesse151@umn.edu, ahesse2567@gmail.com
#     roles:
#       - Investigation
#       - Software
#       - Visualization
#       - Writing – Original Draft Preparation
#     affiliations:
#       - University of Minnesota-Twin Cities
#   - name: Manix White
#     roles:
#       - Data Collection
#     affiliations:
#       - University of Minnesota-Twin Cities
#   - name: Christopher Lundstrom
#     orcid: 0000-0002-1527-1685
#     corresponding: false
#     roles: 
#       - Supervision
#       - Writing – Review & Editing
#     affiliations:
#       - University of Minnesota-Twin Cities
abstract: |
  Cardiopulmonary exercise testing involves collecting variable breath-by-breath data, sometimes requiring data processing of outlier removal, interpolation, and averaging before later analysis. These data processing choices, such as averaging duration, are known to affect calculated values such as VO~2~max. However, assessing the effects of data processing without knowing popular methods worth comparing is difficult. In addition, such details aid study reproduction. We conducted a scoping review of articles with exercise testing that collected data breath-by-breath from three databases. Of the 8,351 articles, 376 (4.5 ± 0.4%) and 581 (7.0 ± 0.5%) described outlier removal and interpolation, respectively. An estimated 66.8 ± 2.8% reported averaging methods (n = 1078). Commonly documented outlier cutoffs were ± 3 or 4 SD (39.1% and 51.6%, respectively). The dominating interpolation duration and procedure were one second (93.9%) and linear interpolation (92.5%). Averaging methods commonly described were 30 (30.9%), 60 (12.4%), 15 (11.6%), 10 (11.0%), and 20 (8.1%) second bin averages. This shows that studies collecting breath-by-breath data often lack detailed descriptions of data processing methods, particularly for outlier removal and interpolation. While averaging methods are more commonly reported, improved documentation across all processing methods will enhance reproducibility and facilitate future research comparing data processing choices.
keywords:
  - Data Averaging
  - Outlier Removal
  - Interpolation
# author-note:
#   disclosures:
#     conflict of interest: "The author has no conflict of interest to declare."
# date: last-modified
bibliography: references.bib
# citation:
#   container-title: "JOURNAL GOES HERE"
number-sections: true
---

```{r, setup, results='hide', echo=FALSE, message=FALSE}
library(tidyverse)
library(janitor)
library(knitr)
library(flextable)
# library(kableExtra)
extrafont::loadfonts(quiet = TRUE)
library(here)
```

# Introduction

Clinicians and researchers commonly use cardiopulmonary exercise testing (CPET) to determine maximal aerobic capacity (VO~2~max), ventilatory thresholds, and VO~2~ kinetics.
Such values help categorize fitness, predict disease risk, and guide exercise [@pescatello2014, p. 162].
Using CPET results to guide exercise, especially relative to thresholds, produces better improvements due to more consistent and predictable metabolic responses [@jamnick2020].
Therefore, incorrectly calculating or identifying these values limits CPET benefits.

Calculating the above values often requires data processing when CPET data is collected breath-by-breath (BBB) as it is highly variable [@robergs2010].
CPET data processing usually involves outlier removal, optional interpolation to regular intervals, and averaging to more accurately reflect whole-body metabolism [@robergs2010].
Previous research has shown that data averaging influences CPET values.
Averaging over longer durations reduces VO~2~max and VO~2~ plateau detection [@robergs2003; @robergs2010; @sousa2010; @johnson1998; @sell2021; @midgley2007; @astorino2009; @astorino2000; @martin-rincon2019; @martin-rincon2020; @scheadler2017; @dejesus2014; @hill2003; @smart2015; @matthews1987].
We are unaware of research on the effects of data processing and locating ventilatory thresholds.

Many studies remove outliers by finding points ±3 or ±4 standard deviations (SD) beyond the local mean (i.e., a prediction interval).
These cutoffs are common because the relatively small sample size of BBB gas exchange data often contains more values beyond 3 or 4 SD than one would predict from an assumed Gaussian distribution [@lamarra1987].
More outliers appear than expected because of both conscious and unconscious alterations of breathing patterns, including swallowing and coughing [@lamarra1987].
We are unaware of prior research that examines how different outlier removal strategies affect VO~2~max, ventilatory thresholds, and VO~2~ kinetics.

Interpolation, often to one-second intervals, is common in VO~2~ kinetics research to "ensemble" average repeated transitions to minimize variability [@keir2014; @lamarra1987].
Although this does not affect parameter estimates, one-second interpolation has been criticized for artificially narrowing confidence intervals [@benson2017; @francescato2014; @francescato2019; @francescato2015].
As before, we are unaware of research specifically investigating how interpolation affects VO~2~max and ventilatory threshold identification.

Data processing choices, such as averaging and interpolation, impact CPET variables or their confidence intervals.
Existing surveys [@robergs2010] and studies [@midgley2007] are small and focused on averaging methods only, finding time-based bin averages (e.g., 30-second averages) were popular.
A larger sample can, therefore, better describe how often all data processing steps are described.

Before conducting this scoping review, we anecdotally observed that many articles using CPET data did not report all data processing steps, especially outlier removal and interpolation details.
This may hamper reproduction or replication attempts, which have become a more prominent issue in science within the past decade [@goodman2016; @opensciencecollaboration2015] Therefore, to assist with conducting future research on the effects of data processing on CPET values and to evaluate the methodological reproducibility of research using BBB gas exchange data generally, we conducted a broad scoping review to identify the frequency of reporting, and popularity of outlier removal, interpolation, and data averaging methods.

# Methods {#sec-methods}

## Design and Eligibility Criteria

This scoping review surveyed gas exchange data processing choices in original, peer-reviewed studies, summarizing the reporting frequency and methods for outlier removal, interpolation, and averaging.
It is based on a dissertation chapter by the first author [-@hesse2023].
These methods [@tricco2018] and results [@peters2020] are modeled on the PRISMA scoping review extension guidelines.
Eligible articles were original, peer-reviewed articles, with BBB gas exchange data, human participants, in English, with a DOI.
We imposed no date restriction.

```{r, article_counts}
source(here("code/cpet_articles/analysis/reporting/selection_sources_evidence.R"))
```

## Information Sources and Search

```{r, n_non_subscribed_articles}
manual_downloads <- read_csv(
    here::here("data/cpet_articles/Manual Downloads - Articles.csv"),
    show_col_types = FALSE)

n_unsubscribed <- manual_downloads %>% 
    count(subscribed) %>% 
    filter(subscribed == FALSE) %>% 
    select(n) %>% 
    pull()
```

We acquired data from the Ovid-MEDLINE, Scopus, and Web of Science databases with the guidance of a university librarian.
The electronic search strategy for the Ovid-MEDLINE database can be found in the supplemental materials.

Our search output comprised article identifiers like DOIs.
To find missing DOIs, we employed the PubMed Central ID Converter API [@ncbi2021] using Python.
Full texts were accessed via publisher text and data mining APIs using Python, unpaywall.org [@unpaywal] using the unpywall Python package, through custom-built web-scraping scripts, or manually.
Our library subscription did not permit access to `r format(n_unsubscribed, big.mark = ',', scientific = FALSE)` articles.

## Selection of Sources of Evidence

This study used a single screening process because it differs from most scoping reviews.
It only requires an exercise test with BBB gas exchange data collection rather than a more complex assessment of the overall methodology and intervention.

### Text Analysis and Screening

Despite database search filters, we screened additional non-English, non-human, and non-original articles such as reviews, meta-analyses, and protocol registrations, in addition to case studies.
We manually analyzed a subset of articles to help build machine learning (ML) classifiers and construct RegExs described below.
These ML classifiers and RegExs helped identify ineligible articles.
This computerized screening required converting full-text PDF and EPUB documents into plain text files.
Plain text files were normalized by transforming text to lowercase, removing hyphenations and extra whitespace, and correcting some plain text conversion-induced errors.

Following the normalization, we identified and removed articles that failed to correctly convert into text format, spotted non-English articles using the fasttext Python module [@bojanowski2016] and employed a random forest classifier from the sklearn Python package [@pedregosa2011] to detect ineligible articles based on our criteria.
We manually reviewed potentially ineligible articles flagged by the ML classifier.

```{r, calc_n_bbb_articles}
ineligible_articles <- read_csv(
    "data/cpet_articles/text_analysis/eligibility/ineligible_articles_combined.csv",
    show_col_types = FALSE)

bbb_articles <- read_csv(
    "data/cpet_articles/text_analysis/all_bbb_articles.csv",
    show_col_types = FALSE) %>% 
    distinct(doi_suffix, .keep_all = TRUE) %>% 
    filter(!(doi_suffix %in% ineligible_articles$doi_suffix))

n_bbb_articles <- nrow(bbb_articles)
```

Next, we identified BBB articles using RegExs.
Articles were considered BBB articles if their text contained variations of the phrase "breath-by-breath", or if their text included the make or model of a known BBB analyzer.
Breath-by-breath brands and analyzers we included were Oxycon and Carefusion brands, Medgraphics Ultima, CPX, CCM, and CardiO~2~ models, Sensormedics Encore and 2900 models, Cosmed quark, k4, and k5 models, and the Minato RM-200, AE-280S, AE-300S, and AE-310S models.
In total, we identified `r format(n_bbb_articles, big.mark = ',', scientific = FALSE)` articles.

Within this subset, we performed a similar RegEx search for studies that documented using Douglas Bags or mixing chambers and excluded those articles.
The full details are described in the "data charting process" section.

### Data Charting Process

RegExs identified the presence of short phrases likely indicating that the authors described these methodological details.
If present, we extracted a "snippet" of text surrounding those phrases for later manual analysis by obtaining approximately 200 surrounding characters.
We then recorded the methods from these snippets.
In all cases, methods were only considered documented if the snippets provided at least some specific information.
For example, articles stating outlying breaths were removed but without describing the outlier criteria were considered "not described." Finally, we read the full-text article to accurately document the data when snippets were ambiguous.

The data charting subsections below provide text extraction examples.
Extracted texts were normalized to lowercase, with end-of-line hyphenation and unnecessary white space removed before capitalizing certain keywords for readability.
Therefore, formatting varies and may include unconventional spacing and Unicode characters.

```{r, n_rand_articles, results='hide'}
z <- qnorm(0.025, lower.tail = FALSE)
margin_of_error <- 0.03
p <- 0.5

n_articles <- ceiling(((margin_of_error / z)^2)^-1 * (p * (1 - p)))

n_rounded_up_nearest_hundred <- round(n_articles, -2)
```

We analyzed all eligible BBB articles for outlier and interpolation methods because fewer articles described these methods (\~5%) and the phrases were more distinct.
In contrast, we analyzed a random subset of articles to document data averaging methods because far more articles described their averaging methods.
Early estimates as we developed our RegExs were that \~60% or `r format(round(0.6 * n_bbb_articles), big.mark = ',', scientific=FALSE)` articles had some averaging details.
Furthermore, the phrases associated with averaging methods are more generic and often refer to other study aspects, such as heart rate averaging periods.
Given the large number of articles, we needed a minimum sample size of `r format(n_articles, big.mark = ',', scientific = FALSE)` based on a 95% confidence interval and a maximum margin of error of ±3%, assuming a proportion of 0.5.
However, we raised this to `r format(n_rounded_up_nearest_hundred, big.mark = ',', scientific = FALSE)` in anticipation of finding ineligible articles that eluded our previous text screening.

#### Outliers

Our outlier RegExs identified phrases like "swallowing", "coughing", "errant", "aberrant", and references to the "local mean," "prediction interval," or a specific standard deviation limit such as ±3 or ±4.
For example, our RegExs found " errant"; " local mean"; and "breath-by-breath ̇vo2 data from each step transition were initially edited to exclude errant breaths by removing values lying more than 4 sd" from @breese2019.
We gathered snippets surrounding those phrases and combined them when overlapping, thus producing

> > y\[hb+mb\] data (quaresima & ferrari, 2009).
> > expressed as 2.5 data analysis and kinetic modelling the breath-by-breath ̇vo2 data from each step transition were initially edited to exclude errant breaths by removing values lying more than 4 sd from the local mean determined using a five-breath rolling\\n\\x0c1932 breese et al. and deoxy\[hb+mb\] responses were subavera

We recorded the outlier limit as ±4 SD and the outlier function as a rolling 5-breath whole mean average.

#### Interpolation

Nearly all articles describing interpolation methods used variations of "interpolate." The remaining phrases were infrequent and inconsistent enough that interpolation methods were only described for those articles when discovered by chance.
To illustrate interpolation documentation, our RegExs extracted the snippet from @hartman2018.

> > the v̇ o2 data from gd and gl exercise bouts were modeled to characterize the oxygen uptake kinetics following the methods described by bell et al. (2001).
> > breath-by-breath v̇ o2 data were linearly INTERPOLATed to provide second-by-second values.
> > phase 1 data (i.e. the cardiodynamic component), from the first ∼20 s of exercise, were omitted from the kinetics analysis because phase 1 is not directly repres

We documented the interpolation type as "linear" and the interpolation time as one second.

#### Averaging

<!-- ![Flowchart depicting the four major components of averaging method documentation.](graphics/Averaging Method Documentation300.jph){#fig-avg_methods_flowchart} -->

We document averaging methods according to five criteria: type/units, subtype/calculation, amount, measure of center, and mean type (Figure 1).
Type/units refer to the averaging units of time, breath, and digital filters.
Subtype/calculation involves specific computations like bin and rolling averages or digital filter forms.
The amount is the unit quantity.
For example, 30 for a time average is 30 seconds but is 30 breaths for a breath average.
Measure of center distinguishes between mean or median, and mean type delineates whole vs. trimmed mean.
Trimmed (truncated) means exclude a number of the highest and lowest values in the quantity before averaging the remaining data.

Descriptions of averaging methods are also considerably more diverse and generic than outlier and interpolation descriptions.
For example, "30-second averages" and "averaged every 30 seconds" invite complexity, leading to more snippets referring to averaging something besides BBB gas exchange data.
Given that, we required that the text snippets include a reference to gas data such as the text "O~2~," "breath," "gas," "ventilation," etc.

In contrast to previous studies, we also documented every averaging method we found per paper instead of only describing the averaging method for VO~2~max.
We also recorded multiple averaging methods when the authors described the sampling interval and the transformation applied to it.
For example, the snippet from @hassinen2008

> > ath method using the vmax respiratory gas analyzer (sensormedics, yorba linda, ca).
> > vo2max was deﬁned as the mean of the three highest values of the averaged oxygen consumption measured consecutively OVER 20-S intervals.
> > a total of 98% of the subjects achieved the respiratory exchange ratio of ⱖ1.1.
> > electrocardiography was recorded throughout the exercise test using cardiosoft software (ge medical systems,

states that oxygen consumption was measured every 20 seconds and that VO~2~max was calculated as the average of three 20-second intervals, or 60-seconds.
For this article, we documented one averaging method as a 20-second time bin whole mean and another as a 60-second time bin whole mean.

In many cases, authors did not explicitly use the terms "average" or "mean" to describe their averaging methods, but we documented their methods when implied.
For example, the snippet from @deboeck2004 reading

> > red using a continuously monitored electrocardiograph.
> > blood pressure was measured at the end of each workload increment using an automatic sphygmomanometer.
> > peak v9o2 was deﬁned as the v9o2 measured DURING THE LAST 30 S of peak exercise.
> > oxygen pulse was calculated by dividing v9o2 by cardiac frequency.
> > the anaerobic threshold was detected using the v-slope method \[16\].
> > the ventilatory equivalent for carbon dioxide w

states they calculated VO~2~peak using the last 30 seconds of exercise data.
We documented such phrasing as a 30-second time-bin whole mean average.

### Data Items

In all cases, articles that did not return any phrases were documented as "not described" for their respective data processing category.
If snippets did not refer to the data processing category or if the snippet lacked sufficient information, those data processing variables were documented as "not described." For example, interpolation variables were denoted as "not described" if interpolation was acknowledged but without details for the interpolation type or time.

#### Outliers

We documented the outlier limit, for example, ±3 standard deviations, and any outlier function used to compute the outlier limit, if described.

#### Interpolation

We recorded the interpolation type (linear, cubic, Lagrange, specifically *un*interpolated, and other) and time frame (e.g., every one second).

#### Averaging

We noted the following averaging types: Time, breath, breath-time, time-breath, time-time, digital filter, ensemble, (explicitly) *un*averaged, and other.
Averaging subtypes included bin, rolling, bin-roll, rolling-bin, Butterworth low-pass, Fast Fourier Transform (FFT), and Savitsky-Golay.
Next, we recorded the time in seconds or the number of breaths.
We recorded the measure of center as mean or median.
Finally, we noted if the mean was a whole or trimmed.

### Synthesis of Results

Counts, percentages, and margin of error (95% confidence) were calculated for the reporting frequency of each data processing method using R [@rcoreteam2021] and RStudio [@positteam2022].

# Results {#sec-results}

## Selection of Sources of Evidence

```{r, selection_sources_evidence}
ovid_records <- read_csv(here::here(
    "data/cpet_articles/database_search/ovid/doi_merged_ovid.csv"),
    show_col_types = FALSE) %>% 
    clean_names()
scopus_records <- read_csv(here::here(
    "data/cpet_articles/database_search/scopus/scopus_records_tidy.csv"),
    show_col_types = FALSE) %>% 
    clean_names()
wos_records <- read_csv(here::here(
    "data/cpet_articles/database_search/web_of_science/web_of_science_records_tidy.csv"), show_col_types = FALSE) %>% 
    clean_names()

n_total_with_na <- bind_rows(ovid_records['doi'],
                    scopus_records['doi'],
                    wos_records['doi']) %>% 
    distinct() %>% 
    nrow()

n_no_doi <- n_total_with_na - n_total_articles
n_no_doi <- if_else(n_no_doi <= 10, 
        english::english(n_no_doi) %>% 
            as.character() %>% 
            str_to_lower(),
        format(n_no_doi, big.mark = ',', scientific = FALSE))
```

Figure 2 shows the selection of sources of evidence flowchart.
During our analysis, we identified `r format(n_ineligible_articles, big.mark = ',', scientific = FALSE)` ineligible articles.
We cross-referenced those against the breath-by-breath articles and removed another `r format(n_ineligible_bbb_articles, big.mark = ',', scientific = FALSE)`, leading to `r format(n_eligible_bbb_articles, big.mark = ',', scientific = FALSE)` articles.

## Characteristics and Results of Individual Sources of Evidence

The PRISMA Extension for Scoping Reviews checklist normally requires a section to report the characteristics and results of individual sources of evidence, usually in a table format, including citations [@tricco2018].
Given the vast nature of this scoping review, readers can instead view web links to our [outlier](https://docs.google.com/spreadsheets/d/1k_i4EP5U3zMltk8n21X-KHGoxUfR6XAJu6lxrVUufg0/edit?usp=sharing), [interpolation](https://docs.google.com/spreadsheets/d/1mNHwyNwVeQeAAm-Jx43ImR91sLyRLSvad9oglHQB83A/edit?usp=sharing), and [averaging](https://docs.google.com/spreadsheets/d/1KdmDZuI1FS1XUK5zJm3JIqf4tQiBd0C1pW0p0PFZweU/edit?usp=sharing) data charting spreadsheets.

## Synthesis of Results

We present our results according to the reporting prevalence followed by the specific characteristics when reported.

### Outliers

```{r, outlier_reporting, message=FALSE, warning=FALSE}
source("code/cpet_articles/analysis/reporting/outlier_reporting.R")
```

```{r, prop_sds}
prop_3sd <- specified_outlier_cutoffs_by_type %>% 
    filter(outlier_limit == "±3 SD / 99%") %>% 
    select(prop) %>% 
    pull()

prop_4sd <- specified_outlier_cutoffs_by_type %>% 
    filter(outlier_limit == "±4 SD") %>% 
    select(prop) %>% 
    pull()
```

Of the `r format(total_articles, big.mark = ',', scientific = FALSE)` articles, `r n_articles_reporting_outliers` (`r prop_articles_reporting_outliers * 100` ± `r round(moe_prop_articles_reporting * 100, 1)`%) reported outlier removal methods.
Of the articles reporting their outlier methods, the most prevalent methods were ±3 (`r sprintf("%.1f", prop_3sd * 100)`%) and ±4 (`r sprintf("%.1f", prop_4sd * 100)`%) standard deviations, respectively (Figure 3).

```{r, outliers_when_reported}
#| label: fig-specified-outlier-limits
#| fig-cap: Counts and percentages of outlier limits when specified.
# plot(prop_outlier_limits_plot)
```

Only `r n_outlier_func_reporting` (`r sprintf("%.1f", prop_outlier_func_reporting * 100)` ± `r sprintf("%.1f", moe_prop_outlier_func_reporting *100)`%) articles reported details of the function they used to calculate their outlier limit.
Of those, breath-based averages (n = `r n_breath_outlier_funcs`, `r prop_breath_outlier_funcs`%) then time-based averages (n = `r  n_time_outlier_funcs`, `r prop_time_outlier_funcs`%) were the most common for calculating outlier boundaries.
Specifically, 5-breath averages (n = `r n_5_breath_func`, `r prop_5_breath_func`%) were the most prevalent functions to calculate outlier limits.

### Interpolation

```{r, interpolation_reporting, warning=FALSE, message=FALSE}
source("code/cpet_articles/analysis/reporting/interpolation_reporting.R")
```

We found that `r count_specified_interpolation` (`r sprintf("%.1f", prop_specified_interpolation * 100)` ± `r sprintf("%.1f", moe_prop_articles_reporting_interpolation * 100)`%) out of `r format(total_articles, big.mark = ',', scientific = FALSE)` specified their interpolation methodology.
When reported, the most common interpolation time was `r as.numeric(most_popular_interpolation_time) %>% english::english() %>% as.character()` second (n = `r n_most_popular_interpolation_time`, `r sprintf("%.1f", prop_most_popular_interpolation_time * 100)`%).
Although the majority of articles reporting interpolation procedures did not explicitly specify their interpolation method (n = `r n_most_popular_interpolation_method`, `r sprintf("%.1f", prop_most_popular_interpolation_method * 100)`%), `r most_popular_stated_interpolation_method` interpolation was the most popular stated method (n = `r n_most_popular_stated_interpolation_method`, `r sprintf("%.1f", prop_most_popular_stated_interpolation_method * 100)`%) (see Table 1 and Figure 4).

```{r, interpolation_tables}
#| label: tbl-interpolation_time_type
#| tbl-cap: Most prevalent specified interpolation methods by type (a) and by time (b).
#| layout-ncol: 2

# interpolation by type
interpolation_by_type_tib_formatted <- 
  interpolation_by_type_tib %>% 
    mutate(prop = round(prop * 100,1),
           interpolation_type = str_to_title(interpolation_type)) %>% 
    rename("Interpolation Type" = interpolation_type,
           N = n,
           "%" = prop) %>% 
    flextable::flextable()

# interpolation by time
interp_by_time_formatted <- interpolation_by_time_tib %>% 
    mutate(interpolation_time_s = if_else(prop < 0.01, "other", interpolation_time_s),
           interpolation_time_s = str_to_sentence(interpolation_time_s)) %>% 
    group_by(interpolation_time_s) %>% 
    summarize(n = sum(n)) %>% 
    ungroup() %>% 
    mutate(prop = round(prop.table(n) * 100, 1)) %>% 
    rename("Interpolation Time (s)" = interpolation_time_s,
           N = n,
           "%" = prop) %>% 
    flextable::flextable()

flextable::save_as_docx(
  interpolation_by_type_tib_formatted,
  interp_by_time_formatted,
  path = here::here("graphics/interp_tables.docx"))


```

```{r, interpolation_plot}
#| label: fig-interpolation_by-time-and_type
#| fig-cap: Most prevalent specified interpolation methods by both type and time.
# plot(condensed_interpolation_by_specified_procedure_plot)
```

### Averaging

```{r, load_avg_data}
source(here::here("code/cpet_articles/analysis/reporting/avg_methods_reporting.R"))
```

```{r, avg_by_type_calcs}
most_popular_avg_type <- avg_by_type_tab %>% 
    filter(n == max(n)) %>% 
    select(avg_type) %>% 
    pull()

most_popular_avg_type_prop <- avg_by_type_tab %>% 
    filter(n == max(n)) %>% 
    select(prop) %>% 
    pull()

second_most_popular_avg_type <- avg_by_type_tab %>% 
    filter(n == sort(n)[length(n) - 1]) %>%
    select(avg_type) %>% 
    pull()

second_most_popular_avg_type_prop <- avg_by_type_tab %>% 
    filter(n == sort(n)[length(n) - 1]) %>% 
    select(prop) %>% 
    pull()
```

```{r, avg_subtype_calcs}
most_popular_avg_subtype <- avg_by_subtype_tab %>% 
    filter(n == max(n)) %>% 
    select(avg_subtype) %>% 
    pull()

most_popular_avg_subtype_prop <- avg_by_subtype_tab %>% 
    filter(n == max(n)) %>% 
    select(prop) %>% 
    pull()

second_most_popular_avg_subtype <- avg_by_subtype_tab %>% 
    filter(n == sort(n)[length(n) - 1]) %>%
    select(avg_subtype) %>% 
    pull()

second_most_popular_avg_subtype_prop <- avg_by_subtype_tab %>% 
    filter(n == sort(n)[length(n) - 1]) %>% 
    select(prop) %>% 
    pull()
```

```{r, top_avg_subtypes}
top_three_type_subtype <- avg_by_type_subtype_tab %>% 
    slice_max(order_by = n, n = 3) %>% 
    select(avg_type_subtype) %>% 
    pull() %>% 
    str_to_lower()

top_three_type_subtype_props <- avg_by_type_subtype_tab %>% 
    slice_max(order_by = n, n = 3) %>% 
    select(prop) %>% 
    pull()
```

After removing `r n_rounded_up_nearest_hundred - n_total_articles_avg` ineligible articles that we discovered during data documentation from the original `r format(n_rounded_up_nearest_hundred, big.mark = ',', scientific = FALSE)` random articles, we analyzed `r format(n_total_articles_avg, big.mark = ',', scientific = FALSE)` articles for our averaging analysis.
We recorded that `r n_reporting_avg_methods` (`r sprintf("%.1f", prop_reporting_avg_methods * 100)` ± `r round(margin_of_error * 100, 1)`%) reported some details of their data averaging methods.
`r str_to_sentence(most_popular_avg_type)` averages dominated in popularity (`r sprintf("%.1f", most_popular_avg_type_prop * 100)`%) (Table 2).
`r most_popular_avg_subtype` averages proved the most widespread averaging subtype (`r sprintf("%.1f", most_popular_avg_subtype_prop * 100)`%) (Table 2).
Together, `r top_three_type_subtype[1]` (`r sprintf("%.1f", top_three_type_subtype_props[1] * 100)`%) was the most frequent type-subtype averaging method combination.

```{r, avg_type_subtype_tables}
#| label: tbl-avg_type_subtype_tables
#| tbl-cap: Averaging methods by type (a) and subtype (b).
#| tbl-cap-location: top
#| layout-ncol: 2

avg_by_type_tab_formatted <- avg_by_type_tab %>% 
    mutate(prop = round(prop * 100, 1)) %>% 
    rename("Averaging Type" = avg_type,
           N = n,
           "%" = prop) %>% 
    flextable::flextable()

avg_by_subtype_tab_formatted <- avg_by_subtype_tab %>% 
    mutate(prop = round(prop * 100, 1),
          avg_subtype = if_else(avg_subtype == "Fft",
                                "Fast Fourier Transform",
                                avg_subtype)) %>% 
    rename("Averaging Subtype" = avg_subtype,
           N = n,
           "%" = prop) %>% 
    arrange(desc(N)) %>% 
    flextable::flextable()

flextable::save_as_docx(
  avg_by_type_tab_formatted,
  avg_by_subtype_tab_formatted,
  path = here::here("graphics/avg_tables.docx"))

```

When incorporating averaging amounts, 30-, 60-, 15-, and 10-second bin averages (Figure 5) were the most popular.
The "other" methods category accounted for the second highest share of the total, but this represents many rarely used averaging methods.

```{r, avg_full_method_plot}
#| label: fig-avg_full_method_plot
#| fig-cap: Prevalence of complete averaging procedures. The numbers in each column label are in seconds for time averages and the number of breaths for breath averages. The "other" column represents methods that accounted for less than 1% of the total stated methods.
# plot(avg_by_full_method_plot)
```

# Discussion {#sec-discussion}

## Summary of Evidence

This review shows that gas exchange data processing methods are infrequently reported for outlier removal and interpolation.
We consider outlier removal documentation important as it applies to many exercise test analyses.
Removing outliers is important to VO~2~ kinetics and similar research with rapid intensity changes because they rely on high temporal resolution.
Outlier removal is also relevant for maximal exercise testing as outliers near the end of a test may influence VO~2~max or VO~2~peak.
Previous research indicates that a VO~2~max below the 20th percentile for age and sex increases the risk of all-cause mortality [@blair1995], so accurate determinations of VO~2~max are important for individuals with low cardiorespiratory fitness: an erroneous breath yielding an overestimated VO~2~max may subdue the urgency to improve cardiovascular health for low-fitness individuals.

Outliers could also affect mathematical VO~2~ plateau determinations.
Such methods test if neighboring VO~2~ values or a VO~2~ vs. time slope does not change or increase by more than a set rate (e.g., 50 mL/min) at the end of a maximal test.
[@robergs2001; @astorino2000; @myers1989; @myers1990; @yoon2007].
Though data averaging dampens their influence, outliers present near the conclusion of a maximal test could plausibly interfere with mathematical VO~2~ plateau determination.

We are currently unaware of research that has tested this, but outliers may interfere with submaximal thresholds found using algorithms, especially if they exist near likely breakpoints.
Threshold algorithms often fit piecewise linear regressions and solve for the lowest sums of squares [@jones1984; @beaver1986; @orr1982].
Points near the edges of the regression lines have more leverage when solving for the best-fit line and, therefore, are more likely to influence the slope or intercept.
Such changes could alter the intersection point of the piecewise regression, and thus, the threshold values.

Finally, even fewer articles reported the outlier limit calculation function.
As the function chosen impacts calculated outlier limit, it also affects where values are considered outliers.
We are unaware of a recommended outlier removal function but encourage stating such details.

We find the low interpolation reporting more reasonable because this procedure is most relevant to less frequent VO~2~ kinetics studies.
However, the V-slope method, one of the most common methods for determining the first ventilatory threshold, interpolates data in their original method [@beaver1986].
Importantly, the V-slope algorithm is only part of the overall V-slope method, so it can be unclear if authors interpolated data when citing the V-slope method.
Given this and the artificial confidence interval shrinkage, it may be prudent for future papers to specify interpolation or lack thereof.

Most studies use one-second linear interpolation, but different time frames and styles, such as cubic interpolation, may yield different results.
Cubic spline interpolation produces a smooth curve but may slightly "overshoot" measured values [@zhang1997].
Though likely small, we recommend authors specify the interpolation type.

Despite a much higher percentage of papers describing at least some of their averaging methods, a third of studies examined in this review neglected to document their process.
Data averaging likely contributes more to the final calculated values of VO~2~max and other variables than do outlier removal and interpolation.
Indeed, the research on the effect of interpolation on VO~2~ kinetics parameters shows that interpolation does not significantly affect the values of parameter estimates [@benson2017; @francescato2014; @francescato2019; @francescato2015].
Although we are unaware of studies comparing the effect of outlier removal or leaving data as-is before proceeding with other calculations, the known impact of data averaging on VO~2~max and the inherent dampening effect of averaging on outliers itself suggests that data averaging is the most important of the three steps when the goal is to reflect the underlying whole-body metabolic rate.
Therefore, researchers should state their gas exchange data averaging methods to improve research reproducibility and study comparisons.

Stating averaging methods can also help correctly classify cardiorespiratory fitness against normative data.
Research by @martin-rincon2020 offers a strategy to compare two VO~2~max values obtained with different averaging methods.
Without such corrections, one could misclassify cardiorespiratory fitness based on VO~2~max if VO~2~max were calculated with a sufficiently different sampling interval than that used to generate the normative data.
Importantly, the normative data offered by the American College of Sports Medicine [@pescatello2014, table 4.9, pp. 88-93] is based on a regression of VO~2~ vs. time-to-exhaustion using a modified Balke protocol and equations developed from @pollock1982 and @pollock1976 (Cooper Institute, personal communication, 9/2021), rather than directly measured.
The system used to create the regression for males [@pollock1976] and females [@pollock1982] averaged the data every minute and every 30 seconds, respectively.
Given that, stating the averaging methods used may allow for better comparisons to normative data.

```{r, recommended_methods_by_robergs}
n_15_breath_roll <- avg_by_full_method_tab %>% 
    filter(avg_type == "breath" & avg_subtype == "rolling" & avg_amount == 15) %>% 
    select(n) %>% 
    pull()

prop_15_breath_roll <- avg_by_full_method_tab %>% 
    filter(avg_type == "breath" & avg_subtype == "rolling" & avg_amount == 15) %>% 
    select(prop) %>% 
    pull()

z <- qnorm(0.025, lower.tail = FALSE)

moe_15_br_rolling <- z * sqrt(
    prop_15_breath_roll * (1 - prop_15_breath_roll) / 
        n_total_articles_avg)

n_low_pass <- avg_by_full_method_tab %>% 
    filter(avg_type == "digital filter" & avg_subtype == "butterworth low-pass") %>% 
    select(n) %>% 
    pull()

prop_low_pass <- avg_by_full_method_tab %>% 
    filter(avg_type == "digital filter" & avg_subtype == "butterworth low-pass") %>% 
    select(prop) %>% 
    pull()

moe_low_pass <- z * sqrt(
    prop_low_pass * (1 - prop_low_pass) / 
        n_total_articles_avg)

top_three_full_method <- avg_by_full_method_tab %>% 
    slice_max(prop, n = 3) %>% 
    select(prop) %>% 
    pull()

avg_by_full_method_tab_condensed <- avg_by_full_method_tab %>% 
    mutate(avg_procedure = paste(
        avg_type, avg_subtype, avg_amount, avg_mos, avg_mean_type, sep = "-"),
        avg_procedure = if_else(prop < 0.01, "Other", str_to_title(avg_procedure))) %>% 
    group_by(avg_procedure) %>% 
    summarize(n = sum(n)) %>% 
    ungroup() %>% 
    mutate(prop = prop.table(n)) %>% 
    mutate(avg_procedure = str_remove(avg_procedure, "-Mean-Whole"),
           avg_procedure = str_remove_all(avg_procedure, "-Na")) %>% 
    arrange(desc(prop))

top_three_full_method <- avg_by_full_method_tab_condensed %>% 
    slice_max(prop, n = 3) %>% 
    select(avg_procedure, prop) %>% 
    deframe()

```

The most frequent, fully specified data averaging method, the 30-second time average, fits the maximum recommended guideline by Robergs [-@robergs2010].
@robergs2010 also recommended the 15-breath rolling average or the low-pass digital filter, but we only documented these methods `r english::english(n_15_breath_roll) %>% as.character()` (`r sprintf("%.1f", prop_15_breath_roll * 100)` ±`r sprintf("%.1f", moe_15_br_rolling * 100)`%) and `r english::english(n_low_pass) %>% as.character()` (`r sprintf("%.1f", prop_low_pass * 100)` ±`r sprintf("%.1f", moe_low_pass * 100)`%) times, respectively.

## Limitations

This study presents the most extensive review of gas exchange data processing methods to date.
However, due to its scope, not every article received a detailed examination, which means some data processing descriptions might have been missed due to the limitations of our RegExs, leading us to categorize these as "not described." Articles that referred to previous works for their data processing techniques were also marked as "not described" for simplicity.
We realize authors must balance adequate methodological documentation with journal word or character limits.
Yet, methodological shortcut citations can mean missing details that prevent readers from fully reproducing the methods used [@standvoss2024].
Next, by chance, we found rare examples of articles using the median as the measure of center as we built our RegExs.
However, we did not document any such cases in our random sample.
A larger sample would likely find these and other rare data averaging methods.
Finally, it is possible that a few ineligible articles eluded our screening.
Taken together, our results are not entirely comprehensive and may slightly underestimate data processing methods' true reporting frequency.

Another limitation of this scoping review is that our results do not indicate how different data processing methods were used.
For example, we did not distinguish if a 60-second time-bin average was used to calculate VO~2~max or a steady-state exercise period.
Therefore, this review cannot estimate the prevalence of different processing methods for specific analyses, such as VO~2~max.
Nevertheless, this is the first study we know of to document data processing methods *besides* those used to calculate VO~2~max.

## Conclusions

This scoping review found that data processing methods were seldom reported for outlier removal and interpolation, and that averaging reporting, though much higher, could further improve.
The results reflect prevalent methods.
While prevalence should not be conflated with quality, knowing the prevalent methods can allow others to test the influence data processing in this field by comparing relevant options.
Finally, we hope these results motivate others to improve their methodological documentation and, thus, reproducibility in this field.

<!-- # Funding {.unnumbered} -->

<!-- We have no funding sources to disclose. -->

<!-- # Acknowledgments {.unnumbered} -->

<!-- We thank Scott Marsalis and Cody Hennesy from the University -->

<!-- of Minnesota Libraries for their advice and support. -->

<!-- # Conflict of Interest {.unnumbered} -->

<!-- The authors declare that they have no conflict of interest. -->

# References {.unnumbered}

::: {#refs}
:::
